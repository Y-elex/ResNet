import os
import torch
import pandas as pd
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch import nn
from tqdm import tqdm
import sys
from collections import defaultdict

sys.path.append('E:/python_code/FER')
from resnet import ResNetBase

data = 'AffectNet'  # ä¿®æ”¹ä¸ºä½ çš„æ•°æ®é›†åç§°

# æ•°æ®é¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# ç”¨äºå±•ç¤ºçš„ emotion_mapï¼ˆä»…å½“ ImageFolder é¡ºåºä¸ä¹‹åŒ¹é…æ—¶æ‰å‡†ç¡®ï¼‰
emotion_map = {
    0: 'Anger', 1: 'Disgust', 2: 'Fear', 3: 'Happy',
    4: 'Sad', 5: 'Surprise', 6: 'Neutral', 7: 'Contempt'
}

# åŠ è½½æ¨¡å‹ç»“æ„
base = ResNetBase(n_blocks=[6, 6, 6], n_channels=[16, 32, 64], bottlenecks=[8, 16, 16], img_channels=3, first_kernel_size=3)
model = nn.Sequential(base, nn.Linear(64, 8))  # è¾“å‡º8ç±»
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model_path = f'E:/python_code/results/models/Resnet/best_model_{data}.pth'
if not os.path.exists(model_path):
    raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {os.path.abspath(model_path)}")

model.load_state_dict(torch.load(model_path, map_location=device))
model.to(device)
model.eval()

# é¢„æµ‹å‡½æ•°
def predict_dataset(root_dir, split_name):
    dataset = datasets.ImageFolder(root=root_dir, transform=transform)
    loader = DataLoader(dataset, batch_size=1, shuffle=False)

    # è·å– ImageFolder çš„çœŸå®ç±»åˆ«æ˜ å°„ (å…³é”®ï¼)
    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}
    
    results = []
    true_labels_all = []
    pred_labels_all = []

    for i, (inputs, labels) in enumerate(tqdm(loader, desc=f"Predicting {split_name}")):
        inputs = inputs.to(device)
        with torch.no_grad():
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)

        img_path, _ = dataset.samples[i]
        image_name = os.path.basename(img_path)
        true_label = labels.item()
        pred_label = predicted.item()

        # ä½¿ç”¨ ImageFolder çš„çœŸå®æ˜ å°„è·å–ç±»åˆ«å
        true_class_name = idx_to_class[true_label]
        pred_class_name = idx_to_class[pred_label]

        # å°è¯•ç”¨ emotion_map è·å–æ›´å‹å¥½çš„åç§°ï¼ˆå¦‚æœæ ‡ç­¾IDåŒ¹é…ï¼‰
        true_class_display = emotion_map.get(true_label, true_class_name)
        pred_class_display = emotion_map.get(pred_label, pred_class_name)

        results.append({
            'id': i,
            'split': split_name,
            'image_name': image_name,
            'true_label': true_label,
            'true_class': true_class_display,
            'pred_label': pred_label,
            'pred_class': pred_class_display
        })

        # æ”¶é›†æ ‡ç­¾ç”¨äºå‡†ç¡®ç‡è®¡ç®—ï¼ˆä½¿ç”¨çœŸå®æ ‡ç­¾IDï¼‰
        true_labels_all.append(true_label)
        pred_labels_all.append(pred_label)

    return results, true_labels_all, pred_labels_all

# ä¸»å‡½æ•°
if __name__ == '__main__':
    dataset_root = f'E:/python_code/Dataset/facial_emotion/AffectNet/{data}'  # ä¿®æ”¹ä¸ºä½ çš„æ•°æ®æ ¹ç›®å½•
    all_results = []
    all_true_labels = []
    all_pred_labels = []

    for split in ['val']:
        split_dir = os.path.join(dataset_root, split)
        if not os.path.exists(split_dir):
            print(f"âš ï¸ è·³è¿‡æœªæ‰¾åˆ°çš„ç›®å½•: {split_dir}")
            continue
        split_results, true_labels, pred_labels = predict_dataset(split_dir, split)
        all_results.extend(split_results)
        all_true_labels.extend(true_labels)
        all_pred_labels.extend(pred_labels)

    # === è®¡ç®—å¹¶æ‰“å°å‡†ç¡®ç‡ ===
    total_correct = sum(1 for t, p in zip(all_true_labels, all_pred_labels) if t == p)
    total_samples = len(all_true_labels)
    overall_acc = total_correct / total_samples if total_samples > 0 else 0.0

    print("\n" + "="*70)
    print(f"ğŸ“Š æ•´ä½“å‡†ç¡®ç‡ (Overall Accuracy): {overall_acc:.4f} ({total_correct}/{total_samples})")
    print("="*70)

    # æ¯ç±»å‡†ç¡®ç‡
    per_class_correct = defaultdict(int)
    per_class_total = defaultdict(int)
    for t, p in zip(all_true_labels, all_pred_labels):
        per_class_total[t] += 1
        if t == p:
            per_class_correct[t] += 1

    # è·å– ImageFolder çš„çœŸå®æ˜ å°„ç”¨äºæ‰“å°
    temp_dataset = datasets.ImageFolder(root=os.path.join(dataset_root, 'val'), transform=transform)
    real_idx_to_class = {v: k for k, v in temp_dataset.class_to_idx.items()}

    print("\nğŸ“ˆ å„ç±»åˆ«è¡¨æƒ…è¯†åˆ«å‡†ç¡®ç‡ (åŸºäº ImageFolder å®é™…ç±»åˆ«é¡ºåº):")
    print("-" * 70)
    for class_id in sorted(per_class_total.keys()):
        class_name = real_idx_to_class[class_id]
        total = per_class_total[class_id]
        correct = per_class_correct[class_id]
        if total > 0:
            acc = correct / total
            print(f"{class_id:>2d} ({class_name:>12}): {acc:.4f} ({correct:>5d}/{total:>5d})")
        else:
            print(f"{class_id:>2d} ({class_name:>12}): N/A      (    0/    0)")
    # ==========================

    # ä¿å­˜ç»“æœåˆ° Excel
    df = pd.DataFrame(all_results)
    output_file = f"predict_{data}_val.xlsx"
    df.to_excel(output_file, index=False)
    print(f"\nâœ… æ‰€æœ‰é¢„æµ‹å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ {output_file}")